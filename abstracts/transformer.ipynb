{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3a70f7",
   "metadata": {},
   "source": [
    "# Build transformer from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ce47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c3ffc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x117b5feb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac274f",
   "metadata": {},
   "source": [
    "## 1. Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d791afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 4\n",
    "input_dim, embed_dim = 2, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95739b09",
   "metadata": {},
   "source": [
    "### 1.1 Test WordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d0620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 2).unsqueeze(0)\n",
    "assert x.shape == (1, 2, 2)\n",
    "\n",
    "we = WordEmbedding(input_dim=input_dim, embed_dim=embed_dim)\n",
    "xe = we(x)\n",
    "assert xe.shape == (1, 2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1213741",
   "metadata": {},
   "source": [
    "### 1.2 Test PositionEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b07658",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionEmbedding(max_seq_len=4, model_dim=embed_dim)\n",
    "xpe = pe(xe)\n",
    "assert xpe.shape == (1, 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793967c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.0000],\n",
       "         [0.8415, 0.5403]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = torch.tensor([[[0.0000, 1.0000], [0.8415, 0.5403]]])\n",
    "pe = PositionEmbedding(max_seq_len=2, model_dim=2)\n",
    "actual = pe.pe\n",
    "assert torch.allclose(expected, actual, 1e-4)\n",
    "actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089374ea",
   "metadata": {},
   "source": [
    "### 1.3 Test MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe151a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1, 2, 6])\n",
      "x: tensor([[[0.2969, 0.8317, 0.1053, 0.2695, 0.3588, 0.1994],\n",
      "         [0.5472, 0.0062, 0.9516, 0.0753, 0.8860, 0.5832]]])\n",
      "y shape: torch.Size([1, 2, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1410, -0.2415, -0.0318,  0.3922, -0.4950, -0.0911],\n",
       "         [ 0.1424, -0.2383, -0.0315,  0.3907, -0.4926, -0.0913]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 6).float().unsqueeze(0)\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "mha = MultiHeadAttention(\n",
    "    input_dim=embed_dim, \n",
    "    n_heads=3, \n",
    "    max_seq_len=max_seq_len,\n",
    ")\n",
    "y = mha(x, is_masked=False)\n",
    "print(f\"y shape: {y.shape}\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bf0079",
   "metadata": {},
   "source": [
    "### 1.4 Test SelfAttentionBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3305be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4230,  0.5208,  0.1785,  0.0954,  0.3441,  0.2695],\n",
       "         [ 0.6548, -0.3133,  1.0914, -0.0742,  1.1456,  0.7610]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sab = SelfAttentionBlock(\n",
    "    input_dim=embed_dim, \n",
    "    n_heads=3, \n",
    "    max_seq_len=max_seq_len,\n",
    ")\n",
    "y = sab(x)\n",
    "assert y.shape == (1, 2, 6)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980edaaf",
   "metadata": {},
   "source": [
    "### 1.5 Test CrossAttentionBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11ad2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4657,  0.6793,  0.2087,  0.4324,  0.3082,  0.9980],\n",
       "         [ 0.8305, -0.1967,  1.0616,  0.1902,  0.8449,  1.2522]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cab = CrossAttentionBlock(\n",
    "    input_dim=embed_dim, \n",
    "    n_heads=3, \n",
    "    max_seq_len=max_seq_len,\n",
    ")\n",
    "h = torch.rand(x.shape)\n",
    "y = cab(x, h)\n",
    "assert y.shape == (1, 2, 6)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800de677",
   "metadata": {},
   "source": [
    "### 1.6 Test FeedForwardBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70820dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1941,  0.3956,  0.2387,  0.4547,  0.7300,  0.1099],\n",
       "         [ 0.6936, -0.4001,  0.9455,  0.0020,  1.0205,  0.8613]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = FeedForwardBlock(\n",
    "    input_dim=embed_dim,\n",
    "    hidden_dim=2*embed_dim,\n",
    "    output_dim=embed_dim,\n",
    ")\n",
    "y = ffn(x)\n",
    "assert y.shape == (1, 2, 6)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d9d13a",
   "metadata": {},
   "source": [
    "### 1.7 Test Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67d1fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0229,  0.6373,  0.9636,  0.5993,  1.0467,  0.6053],\n",
       "         [ 0.2535, -0.0047,  1.0777, -0.2200,  1.0148,  1.1037]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(\n",
    "    input_dim=embed_dim, \n",
    "    ffn_hidden_dim=2*embed_dim,\n",
    "    n_heads=3, \n",
    "    max_seq_len=max_seq_len\n",
    ")\n",
    "y = encoder(x)\n",
    "assert y.shape == (1, 2, 6)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e5168",
   "metadata": {},
   "source": [
    "### 1.8 Test Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600c5517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4443,  0.4832,  0.6520, -0.1377,  0.9540,  0.2160],\n",
       "         [ 0.6955, -0.1804,  1.1963, -0.3065,  1.6590,  0.4834]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(\n",
    "    input_dim=embed_dim, \n",
    "    ffn_hidden_dim=2*embed_dim,\n",
    "    n_heads=3, \n",
    "    max_seq_len=max_seq_len\n",
    ")\n",
    "y = decoder(x, h)\n",
    "assert y.shape == (1, 2, 6)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c89511",
   "metadata": {},
   "source": [
    "### 1.9 Test Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb59fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = Encoders(\n",
    "    n_layers = 2,\n",
    "    input_dim = input_dim, \n",
    "    embed_dim = embed_dim,\n",
    "    ffn_hidden_dim = 2 * embed_dim,\n",
    "    n_heads = 3, \n",
    "    max_seq_len = 4,\n",
    "    dropout_rate = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19980b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4552,  0.7041, -0.2659,  0.0997, -0.7425,  1.6597],\n",
       "         [ 1.0727, -1.0704, -0.2171,  0.3087, -1.3805,  1.2866]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 2).float().unsqueeze(0)\n",
    "y = encoders(x)\n",
    "assert y.shape == (1, 2, 6)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508490c",
   "metadata": {},
   "source": [
    "### 1.10 Test Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82bf70ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3198,  0.5929],\n",
       "         [-0.4275,  0.0638]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoders = Decoders(\n",
    "    n_layers = 1,\n",
    "    input_dim = input_dim, \n",
    "    embed_dim = embed_dim,\n",
    "    ffn_hidden_dim = 2 * embed_dim,\n",
    "    n_heads = 3, \n",
    "    max_seq_len = 4,\n",
    "    dropout_rate = 0.1\n",
    ")\n",
    "h = torch.rand(2, embed_dim).float().unsqueeze(0)\n",
    "y = decoders(x, h)\n",
    "assert y.shape == (1, 2, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03461180",
   "metadata": {},
   "source": [
    "### 1.11 Test Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c8166db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3497,  0.3230],\n",
       "         [-0.1306,  0.2206]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers = 1,\n",
    "    input_dim = input_dim, \n",
    "    embed_dim = embed_dim,\n",
    "    ffn_hidden_dim = 2 * embed_dim,\n",
    "    n_heads = 3, \n",
    "    max_seq_len = 4,\n",
    "    dropout_rate = 0.1\n",
    ")\n",
    "y = transformer(x)\n",
    "assert y.shape == (1, 2, 2)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
